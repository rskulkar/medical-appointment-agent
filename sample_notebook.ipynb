{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f94a5585",
   "metadata": {},
   "source": [
    "# CHECK WHICH GEMINI MODELS ARE AVAILABLE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16a7f842",
   "metadata": {},
   "source": [
    "# Install/upgrade packages \n",
    "!pip install --upgrade google-generativeai langchain-google-genai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8100d7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check what's available\n",
    "import google.generativeai as genai\n",
    "import os\n",
    "from getpass import getpass\n",
    "\n",
    "# Get API key\n",
    "if \"GOOGLE_API_KEY\" not in os.environ:\n",
    "    api_key = getpass(\"Enter your Google API Key: \")\n",
    "    os.environ[\"GOOGLE_API_KEY\"] = api_key\n",
    "\n",
    "# Configure and list models\n",
    "genai.configure(api_key=os.environ[\"GOOGLE_API_KEY\"])\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"Available Gemini models:\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "available_models = []\n",
    "for model in genai.list_models():\n",
    "    if 'generateContent' in model.supported_generation_methods:\n",
    "        model_name = model.name.replace('models/', '')\n",
    "        available_models.append(model_name)\n",
    "        print(f\"‚úÖ {model_name}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(f\"Found {len(available_models)} available models\")\n",
    "print(\"=\" * 70)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e665cf03",
   "metadata": {},
   "source": [
    "# GOAL ORIENTED PROMPT APPROACH - SUCCESS AND FAILURE CASES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b36b7124",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rajeevkulkarni/Library/Python/3.9/lib/python/site-packages/google/api_core/_python_version_support.py:246: FutureWarning: You are using a non-supported Python version (3.9.6). Google will not post any further updates to google.api_core supporting this Python version. Please upgrade to the latest Python version, or at least Python 3.10, and then update google.api_core.\n",
      "  warnings.warn(message, FutureWarning)\n",
      "/Users/rajeevkulkarni/Library/Python/3.9/lib/python/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n",
      "/Users/rajeevkulkarni/Library/Python/3.9/lib/python/site-packages/google/auth/__init__.py:54: FutureWarning: You are using a Python version 3.9 past its end of life. Google will update google-auth with critical bug fixes on a best-effort basis, but not with any other fixes or features. Please upgrade your Python version, and then update google-auth.\n",
      "  warnings.warn(eol_message.format(\"3.9\"), FutureWarning)\n",
      "/Users/rajeevkulkarni/Library/Python/3.9/lib/python/site-packages/google/oauth2/__init__.py:40: FutureWarning: You are using a Python version 3.9 past its end of life. Google will update google-auth with critical bug fixes on a best-effort basis, but not with any other fixes or features. Please upgrade your Python version, and then update google-auth.\n",
      "  warnings.warn(eol_message.format(\"3.9\"), FutureWarning)\n",
      "/Users/rajeevkulkarni/Library/Python/3.9/lib/python/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "import os\n",
    "from getpass import getpass\n",
    "from IPython.display import display, Markdown\n",
    "\n",
    "from medical_appointment_agent import (\n",
    "    get_rate_limit_safe_llm,\n",
    "    create_task_oriented_agent,\n",
    "    create_goal_oriented_agent,\n",
    "    run_task_oriented_workflow,\n",
    "    create_llm_with_fallback,\n",
    "    RateLimitError,\n",
    ")\n",
    "\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eac915b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ü§ñ Initializing LLM with model: gemini-2.5-flash\n",
      "‚úÖ Successfully initialized with gemini-2.5-flash\n"
     ]
    }
   ],
   "source": [
    "# Setup available (rate limit safe) LLM from Gemini\n",
    "api_key = getpass(\"Enter your Google API Key: \")\n",
    "os.environ[\"GOOGLE_API_KEY\"] = api_key\n",
    "\n",
    "llm = get_rate_limit_safe_llm(verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2ef9e275",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mAction: FindDoctorsTool\n",
      "Action Input: Cardiology\u001b[0m\u001b[36;1m\u001b[1;3mAvailable doctors in Cardiology: Dr. Patel, Dr. Lee, Dr. Martinez, Dr. Johnson\u001b[0m\u001b[32;1m\u001b[1;3mAction: CheckAvailabilityTool\n",
      "Action Input: Dr. Patel\u001b[0m\u001b[33;1m\u001b[1;3mAvailable slots for Dr. Patel: Jan 21 9AM, Jan 22 2PM, Jan 24 10AM, Jan 25 3PM\u001b[0m\u001b[32;1m\u001b[1;3mAction: BookAppointmentTool\n",
      "Action Input: Dr. Patel for Jan 21 9AM\u001b[0m\u001b[38;5;200m\u001b[1;3m‚úÖ Appointment booked: Dr. Patel for Jan 21 9AM\u001b[0m\u001b[32;1m\u001b[1;3mgoal is complete\n",
      "Final Answer: Your appointment with Dr. Patel has been booked for Jan 21 9AM.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "üìã FINAL RESULT:\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "Your appointment with Dr. Patel has been booked for Jan 21 9AM."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "goal_agent = create_goal_oriented_agent(llm)\n",
    "# Single goal request\n",
    "response = goal_agent.invoke({\n",
    "    \"input\": \"Book me an appointment with a cardiologist\"\n",
    "})\n",
    "print(\"\\nüìã FINAL RESULT:\")\n",
    "display(Markdown(response[\"output\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c7791a2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b017fbfd",
   "metadata": {},
   "source": [
    "# TASK ORIENTED PROMPT APPROACH - SUCCESS AND FAILURE CASES "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3885330a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup\n",
    "# api_key = getpass(\"Enter your Google API Key: \")\n",
    "# os.environ[\"GOOGLE_API_KEY\"] = api_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "274513eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ü§ñ Initializing LLM with model: gemini-2.5-flash\n",
      "‚úÖ Successfully initialized with gemini-2.5-flash\n",
      "======================================================================\n",
      "WORKFLOW: Find cardiologists ‚Üí Check Availability ‚Üí Book Appointment\n",
      "======================================================================\n",
      "\n",
      "======================================================================\n",
      "STEP 1: Find cardiologists\n",
      "======================================================================\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mAction: FindDoctorsTool\n",
      "Action Input: Cardiology\u001b[0m\u001b[36;1m\u001b[1;3mAvailable doctors in Cardiology: Dr. Patel, Dr. Lee, Dr. Martinez, Dr. Johnson\u001b[0m\u001b[32;1m\u001b[1;3mI have the answer\n",
      "Final Answer: Available doctors in Cardiology: Dr. Patel, Dr. Lee, Dr. Martinez, Dr. Johnson\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "üìã OUTPUT: Available doctors in Cardiology: Dr. Patel, Dr. Lee, Dr. Martinez, Dr. Johnson\n",
      "\n",
      "‚úÖ Found 4 doctor(s): Dr. Johnson, Dr. Martinez, Dr. Patel, Dr. Lee\n",
      "\n",
      "======================================================================\n",
      "STEP 2: Check availability for Dr. Johnson\n",
      "======================================================================\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/rate-limit. \n",
      "* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 5, model: gemini-2.5-flash\n",
      "Please retry in 58.294755746s. [links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-2.5-flash\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 5\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 58\n",
      "}\n",
      "].\n",
      "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/rate-limit. \n",
      "* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 5, model: gemini-2.5-flash\n",
      "Please retry in 55.974352578s. [links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-2.5-flash\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 5\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 55\n",
      "}\n",
      "].\n",
      "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 8.0 seconds as it raised ResourceExhausted: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/rate-limit. \n",
      "* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 5, model: gemini-2.5-flash\n",
      "Please retry in 51.615451624s. [links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-2.5-flash\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 5\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 51\n",
      "}\n",
      "].\n",
      "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 16.0 seconds as it raised ResourceExhausted: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/rate-limit. \n",
      "* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 5, model: gemini-2.5-flash\n",
      "Please retry in 43.220573427s. [links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-2.5-flash\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 5\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 43\n",
      "}\n",
      "].\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32;1m\u001b[1;3mAction: CheckAvailabilityTool\n",
      "Action Input: Dr. Johnson\u001b[0m\u001b[33;1m\u001b[1;3mAvailable slots for Dr. Johnson: Jan 20 2PM, Jan 22 10AM, Jan 25 1PM, Jan 27 11AM\u001b[0m\u001b[32;1m\u001b[1;3mI have the answer\n",
      "Final Answer: Available slots for Dr. Johnson: Jan 20 2PM, Jan 22 10AM, Jan 25 1PM, Jan 27 11AM\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "üìã OUTPUT: Available slots for Dr. Johnson: Jan 20 2PM, Jan 22 10AM, Jan 25 1PM, Jan 27 11AM\n",
      "\n",
      "‚úÖ Found available slot: Jan 27 11AM\n",
      "\n",
      "======================================================================\n",
      "STEP 3: Book appointment with Dr. Johnson at Jan 27 11AM\n",
      "======================================================================\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mAction: BookAppointmentTool\n",
      "Action Input: Dr. Johnson for Jan 27 11AM\u001b[0m\u001b[38;5;200m\u001b[1;3m‚úÖ Appointment booked: Dr. Johnson for Jan 27 11AM\u001b[0m\u001b[32;1m\u001b[1;3mFinal Answer: ‚úÖ Appointment booked: Dr. Johnson for Jan 27 11AM\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "üìã OUTPUT: ‚úÖ Appointment booked: Dr. Johnson for Jan 27 11AM\n",
      "\n",
      "‚úÖ WORKFLOW COMPLETED SUCCESSFULLY!\n",
      "   Doctor: Dr. Johnson\n",
      "   Specialty: cardiologists\n",
      "   Time: Jan 27 11AM\n",
      "{'success': True, 'specialty': 'cardiologists', 'doctor': 'Dr. Johnson', 'time_slot': 'Jan 27 11AM', 'error': None}\n"
     ]
    }
   ],
   "source": [
    "## Success Case # 1\n",
    "# Try with automatic model fallback\n",
    "try:\n",
    "    llm = create_llm_with_fallback(verbose=True)\n",
    "    agent = create_task_oriented_agent(llm)\n",
    "    result = run_task_oriented_workflow(agent, \"cardiologists\")\n",
    "    print(result)\n",
    "    \n",
    "except RateLimitError as e:\n",
    "    print(f\"\\n‚ö†Ô∏è  {e}\")\n",
    "    print(\"üí§ Waiting 60 seconds before retrying...\")\n",
    "    time.sleep(60)\n",
    "    \n",
    "    # Retry\n",
    "    llm = create_llm_with_fallback(verbose=True)\n",
    "    agent = create_task_oriented_agent(llm)\n",
    "    result = run_task_oriented_workflow(agent, \"cardiologists\")\n",
    "    print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05b2a1fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Success Case # 2\n",
    "result = run_task_oriented_workflow(agent, \"heart specialists\")\n",
    "display(Markdown(result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "06949e36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ü§ñ Initializing LLM with model: gemini-2.5-flash\n",
      "‚úÖ Successfully initialized with gemini-2.5-flash\n",
      "======================================================================\n",
      "WORKFLOW: Find dermatologist ‚Üí Check Availability ‚Üí Book Appointment\n",
      "======================================================================\n",
      "\n",
      "======================================================================\n",
      "STEP 1: Find dermatologist\n",
      "======================================================================\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mAction: FindDoctorsTool\n",
      "Action Input: dermatologist\u001b[0m\u001b[36;1m\u001b[1;3mERROR: No doctors found for specialty: Dermatology\u001b[0m\u001b[32;1m\u001b[1;3mI have the answer\n",
      "Final Answer: ERROR: No doctors found for specialty: Dermatology\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "üìã OUTPUT: ERROR: No doctors found for specialty: Dermatology\n",
      "\n",
      "‚ùå WORKFLOW STOPPED: No doctors found. Steps 2 and 3 will not execute.\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'output'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 18\u001b[0m\n\u001b[1;32m     15\u001b[0m     agent \u001b[38;5;241m=\u001b[39m create_task_oriented_agent(llm)\n\u001b[1;32m     16\u001b[0m     result \u001b[38;5;241m=\u001b[39m run_task_oriented_workflow(agent, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdermatologist\u001b[39m\u001b[38;5;124m\"\u001b[39m)  \u001b[38;5;66;03m# Not available\u001b[39;00m\n\u001b[0;32m---> 18\u001b[0m display(Markdown(\u001b[43mresult\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43moutput\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m))\n",
      "\u001b[0;31mKeyError\u001b[0m: 'output'"
     ]
    }
   ],
   "source": [
    "## Failure case # 1\n",
    "# Try with automatic model fallback\n",
    "try:\n",
    "    llm = create_llm_with_fallback(verbose=True)\n",
    "    agent = create_task_oriented_agent(llm)\n",
    "    result = run_task_oriented_workflow(agent, \"dermatologist\")  # Not available\n",
    "    \n",
    "except RateLimitError as e:\n",
    "    print(f\"\\n‚ö†Ô∏è  {e}\")\n",
    "    print(\"üí§ Waiting 60 seconds before retrying...\")\n",
    "    time.sleep(60)\n",
    "    \n",
    "    # Retry\n",
    "    llm = create_llm_with_fallback(verbose=True)\n",
    "    agent = create_task_oriented_agent(llm)\n",
    "    result = run_task_oriented_workflow(agent, \"dermatologist\")  # Not available\n",
    "\n",
    "display(Markdown(result['output']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a720b6b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Failure case # 2\n",
    "result = run_task_oriented_workflow(agent, \"urologist\")      # Not available\n",
    "display(Markdown(result))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
